import feedparser
import datetime
import os
import requests
import re

# ==========================================
# [ë³´ì•ˆ ë‰´ìŠ¤ ì†ŒìŠ¤ ëŒ€ëŸ‰ ì¶”ê°€ (ë‹¤ì¤‘ ì†ŒìŠ¤)]
# ==========================================
RSS_FEEDS = {
    "ğŸš¨ CISA (US-CERT)": "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json", # JSON ì²˜ë¦¬ ë¡œì§ í•„ìš”í•˜ë‚˜ RSSë¡œ ëŒ€ì²´
    "ğŸ”¥ The Hacker News": "https://feeds.feedburner.com/TheHackersNews",
    "ğŸ›¡ï¸ NIST NVD (General)": "https://nvd.nist.gov/feeds/xml/cve/misc/nvd-rss.xml",
    "âš ï¸ ThreatPost": "https://threatpost.com/feed/"
}

# ë´‡ íƒì§€ ìš°íšŒë¥¼ ìœ„í•œ ê°€ì§œ í—¤ë”
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

def fetch_feed_data(url):
    """User-Agent í—¤ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ RSS í”¼ë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´"""
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        if response.status_code == 200:
            return response.content
    except Exception as e:
        print(f"âŒ Error fetching {url}: {e}")
    return None

def fetch_security_news():
    print("ğŸ“¡ Fetching security news from multiple sources...")
    
    combined_news = ""
    
    # ì—¬ëŸ¬ ì†ŒìŠ¤ ìˆœíšŒ
    for source_name, url in RSS_FEEDS.items():
        print(f"   Trying {source_name}...")
        try:
            # 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            raw_data = fetch_feed_data(url)
            if not raw_data:
                continue

            # 2. íŒŒì‹±
            feed = feedparser.parse(raw_data)
            
            if not feed.entries:
                continue

            # 3. ë‰´ìŠ¤ ì •ë¦¬ (ì†ŒìŠ¤ë³„ ìµœì‹  3ê°œ)
            combined_news += f"\n### {source_name}\n"
            for entry in feed.entries[:3]:
                title = entry.title
                link = entry.link
                # ë‚ ì§œ ì²˜ë¦¬
                published = "Recent"
                if hasattr(entry, 'published'):
                    published = entry.published[:16] # ë‚ ì§œ í¬ë§· ë‹¨ìˆœí™”
                
                combined_news += f"- **[{published}]** [{title}]({link})\n"
                
        except Exception as e:
            print(f"âš ï¸ Failed to parse {source_name}: {e}")
            continue

    return combined_news

def update_security_trends(news_content):
    file_path = "SECURITY_TRENDS.md"
    today = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    if not news_content:
        news_content = "\n> **Note**: í˜„ì¬ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë³´ì•ˆ ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ ì ‘ì†ì´ ì¼ì‹œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n"

    header = f"""# ğŸš¨ Real-time Security Threat Intelligence
> **Defender Bot Status**: ğŸŸ¢ Online & Monitoring  
> **Last Updated**: {today}

ì´ í˜ì´ì§€ëŠ” **Defender Bot**ì´ ì „ ì„¸ê³„ ì£¼ìš” ë³´ì•ˆ í”¼ë“œ(CISA, HackerNews ë“±)ë¥¼ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

---

## âš¡ Global Security Alerts
"""
    
    footer = """
---
## ğŸ¤– Bot Logic
1. **Monitor**: CISA, NIST, ThreatPost RSS Feeds.
2. **Analyze**: Parse latest 3 critical items per source.
3. **Report**: Auto-commit & Merge to Repository.

_Automated by GitHub Actions & Python_
"""
    
    full_content = header + news_content + footer
    
    # íŒŒì¼ ì“°ê¸° (ë¬´ì¡°ê±´ ì‹¤í–‰)
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(full_content)
    
    print(f"âœ… {file_path} has been successfully generated/updated.")

if __name__ == "__main__":
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    news = fetch_security_news()
    
    # íŒŒì¼ ìƒì„± (ë‰´ìŠ¤ê°€ ì—†ì–´ë„ ë¹ˆ íŒŒì¼ì´ë¼ë„ ìƒì„±í•˜ì—¬ git ì—ëŸ¬ ë°©ì§€)
    update_security_trends(news)
